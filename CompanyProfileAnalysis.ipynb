{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qfgWkLygkKt_",
        "outputId": "cd0da244-a9fd-4abf-c727-9e76b7a84d09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Cannot install langchain-community==0.0.38, langchain-core, langchain-google-genai==1.0.7 and langchain==0.1.20 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.39.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.111.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==1.1.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.1.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.4)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.1.1->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.1.1->gradio) (11.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.0.4)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (2.2.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.22.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.7.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.1.20 langchain-core>=0.2.9 langchain-community==0.0.38 langchain-google-genai==1.0.7\n",
        "!pip install gradio\n",
        "!pip install --q -U crewai\n",
        "!pip install --q -U duckduckgo-search\n",
        "!pip install --q langchain_google_genai\n",
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJLmLwlhk1ws"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.agents import Tool\n",
        "import gradio as gr\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "from langchain.utilities import GoogleSerperAPIWrapper\n",
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain.utilities import WikipediaAPIWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5miwiPaIlCtg"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model = \"gemini-pro\",\n",
        "                             verbose = True,\n",
        "                             temperatur = 0.6,\n",
        "                             google_api_key = \"AIzaSyDGpBP2fa8IIZwtpx7eXsknAPsIni89WEE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5mf9-VXAu8D"
      },
      "outputs": [],
      "source": [
        "search_tool = []\n",
        "agents = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRRSAe-ZpRHy"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "ddg = DuckDuckGoSearchRun()\n",
        "search_tool.append(\n",
        "    Tool(\n",
        "        name=\"DuckDuckGoSearch\",\n",
        "        func=ddg.run,\n",
        "        description=\"Useful for browsing information from the internet.\",\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPAUJe9L4lPD"
      },
      "outputs": [],
      "source": [
        "os.environ[\"SERPER_API_KEY\"] = \"ef1fac6e5dbb3596ff0acb351b3c05bdcab47aba\"\n",
        "os.environ[\"GEMINI_PRO_API_KEY\" ]= \"AIzaSyDGpBP2fa8IIZwtpx7eXsknAPsIni89WEE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbtrW6jrDiy1"
      },
      "outputs": [],
      "source": [
        "google_search = GoogleSerperAPIWrapper()\n",
        "search_tool.append(\n",
        "    Tool(\n",
        "        name=\"Google Search\",\n",
        "        func=lambda query: google_search.run(query, config={\"api_key\": os.getenv(\"SERPER_API_KEY\")}),\n",
        "        description=\"Useful to search in Google. Use by default.\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh0mHw6hHcVf"
      },
      "outputs": [],
      "source": [
        "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "search_tool.append(\n",
        "   Tool(\n",
        "       name=\"Wikipedia Search\",\n",
        "       func=wikipedia.run,\n",
        "       description=\"Useful when users request biographies or historical moments.\",\n",
        "   )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgjZt91adz9d"
      },
      "outputs": [],
      "source": [
        "# to ensure the tools are not empty\n",
        "if not search_tool:\n",
        "    raise ValueError(\"Search tools are not initialized properly.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-1scJmcEm5x",
        "outputId": "342b4e3a-b261-495f-c44a-44337338e83e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tool(name='DuckDuckGoSearch', description='Useful for browsing information from the internet.', func=<bound method BaseTool.run of DuckDuckGoSearchRun()>),\n",
              " Tool(name='Google Search', description='Useful to search in Google. Use by default.', func=<function <lambda> at 0x79d96834da20>),\n",
              " Tool(name='Wikipedia Search', description='Useful when users request biographies or historical moments.', func=<bound method BaseTool.run of WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.10/dist-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000))>)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "search_tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoiPt-s5tZGH"
      },
      "outputs": [],
      "source": [
        "def create_agent(role, goal, backstory):\n",
        "    return Agent(\n",
        "        role=role,\n",
        "        goal=goal,\n",
        "        backstory=backstory,\n",
        "        verbose=True,\n",
        "        allow_delegation=False,\n",
        "        llm=llm,\n",
        "        tools=search_tool,\n",
        "        iteration_limit=500,\n",
        "        time_limit=1200,\n",
        "        max_iter=10\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkFkf7sclM2X"
      },
      "outputs": [],
      "source": [
        "# Create agents\n",
        "company_mission_analyst = create_agent(\n",
        "    \"Company Mission, History and Core Values Analyst\",\n",
        "    \"Look for the company's mission statement, history, and core values for {company_name}.\",\n",
        "    \"\"\"You are a company mission and history analyst whose role is to understand and communicate the historical development, mission, and core values of {company_name}.\n",
        "    You need to research and document the company's founding, key milestones, and significant achievements over the years.\n",
        "    You need to analyze how the company's mission and values have evolved and how they align with its current business strategy.\n",
        "    You are an expert in historical research and corporate analysis, capable of compiling comprehensive reports and narratives.\n",
        "    You need to extract detailed historical data, mission statements, and value propositions for {company_name} for 2024.\n",
        "    ONLY use data scraped from the internet for your analysis. Also provide the links where the data is sourced.\n",
        "    Extract everything in more detail.\n",
        "    If data is not available for 2024, then search for data from 2023 or previous years but ensure it is the latest report available.\n",
        "    Keep only those statements or sentences which are available on the internet, discard the sentences which are not available on the internet.\"\"\"\n",
        ")\n",
        "agents.append(company_mission_analyst)\n",
        "\n",
        "financial_analyst = create_agent(\n",
        "    \"Financial Analyst\",\n",
        "    \"Gather comprehensive financial reports and data about {company_name}, including income statements, annual reports, cash flow statements, and balance sheets.\",\n",
        "    \"\"\"You are from finance department who extracts company revenue.\n",
        "    You are responsible for recording financial transactions, preparing financial statements like the income statement and balance sheet, and analyzing financial data.\n",
        "    You need to extract sales figures, revenue of the company and its breakdown.\n",
        "    You need to extract overall income generated by the company from its sales of goods or services.\n",
        "    You need to extract revenue over days, weeks, months, quarters, or years to identify trends and seasonality.\n",
        "    You need to extract revenue by customer type (e.g., demographics, industry) can reveal profitable customer segments.\n",
        "    You need to extract revenue by region, state, or country to understand geographical trends.\n",
        "    But you need to find these details for {company_name}\"\"\"\n",
        ")\n",
        "agents.append(financial_analyst)\n",
        "\n",
        "market_data_analyst = create_agent(\n",
        "    \"Market Data Analyst\",\n",
        "    \"Gather comprehensive market data about {company_name} such as stock prices, market capitalization, P/E ratios, and other relevant metrics.\",\n",
        "    \"\"\"You are a market data analyst whose primary role is to gather, analyze, and interpret market trends and data to support strategic business decisions.\n",
        "    You need to focus on market trends, consumer behavior, and competitive analysis to provide insights that will drive business strategies.\n",
        "    You need to monitor and analyze economic indicators, market reports, and industry news to identify opportunities and threats in the market.\n",
        "    You are an expert at using statistical software and data visualization tools to present your findings clearly and effectively.\n",
        "    You need to extract key market data and trends from industry reports, press releases, and market research studies.\n",
        "    You need to extract and compile market data and trends for {company_name} for 2024.\n",
        "    ONLY use data scraped from the internet for your reports. Also provide the links where the data is sourced.\n",
        "    Extract everything in more detail.\n",
        "    If data is not available for 2024, then search for data from 2023 or previous years but ensure it is the latest report available.\"\"\"\n",
        ")\n",
        "agents.append(market_data_analyst)\n",
        "\n",
        "media_analyst = create_agent(\n",
        "    \"Media Analyst\",\n",
        "    \"Collect news articles and analyze the press presence of {company_name}, including industry news, analyst opinion, and media coverage.\",\n",
        "    \"\"\"You are a media analyst responsible for tracking and analyzing media coverage and trends to provide insights for public relations and marketing strategies.\n",
        "    You need to monitor media mentions, sentiment, and the overall impact of media campaigns for {company_name}.\n",
        "    You need to analyze social media platforms, news articles, press releases, and other media sources to understand public perception and media effectiveness.\n",
        "    You are an expert in media monitoring tools and analytics platforms to track media coverage and measure its impact.\n",
        "    You need to extract media coverage, mentions, and sentiment analysis for {company_name} for 2024.\n",
        "    ONLY use data scraped from the internet for your analysis. Also provide the links where the data is sourced.\n",
        "    Extract everything in more detail.\n",
        "    If data is not available for 2024, then search for data from 2023 or previous years but ensure it is the latest report available.\n",
        "    Keep only those statements or sentences which are available on the internet, discard the sentences which are not available on the internet.\"\"\"\n",
        ")\n",
        "agents.append(media_analyst)\n",
        "\n",
        "business_relationships_analyst = create_agent(\n",
        "    \"Business Relationships Analyst\",\n",
        "    \"Collect information about the customers and suppliers of {company_name}, including key contracts, partnerships, and any relevant details.\",\n",
        "    \"\"\"You are a business relations analyst whose role is to foster and maintain relationships with key business partners, stakeholders, and clients.\n",
        "    You need to identify potential business opportunities, partnerships, and collaborations that align with the strategic goals of {company_name}.\n",
        "    You need to monitor and analyze business news, press releases, and industry reports to understand the business landscape and identify key players.\n",
        "    You are an expert in communication and negotiation, capable of representing {company_name} in various business meetings and discussions.\n",
        "    You need to extract information on business partnerships, collaborations, and major deals for {company_name} for 2024.\n",
        "    ONLY use data scraped from the internet for your analysis. Also provide the links where the data is sourced.\n",
        "    Extract everything in more detail.\n",
        "    If data is not available for 2024, then search for data from 2023 or previous years but ensure it is the latest report available.\n",
        "    Keep only those statements or sentences which are available on the internet, discard the sentences which are not available on the internet.\"\"\"\n",
        ")\n",
        "agents.append(business_relationships_analyst)\n",
        "\n",
        "partnership_analyst = create_agent(\n",
        "    \"Partnership Analyst\",\n",
        "    \"Collect information about the partnerships and alliances of {company_name}, including key partnerships, strategic alliances, and any relevant details.\",\n",
        "    \"\"\"You are a partnership analyst responsible for identifying, evaluating, and managing strategic partnerships that align with the goals of {company_name}.\n",
        "    You need to analyze potential partners' business models, market positions, and strategic fit to ensure mutually beneficial relationships.\n",
        "    You need to monitor and evaluate existing partnerships, providing insights on performance and opportunities for improvement.\n",
        "    You are an expert in using analytical tools and methodologies to assess partnership opportunities and risks.\n",
        "    You need to extract information on potential and existing partnerships, collaborations, and strategic alliances for {company_name} for 2024.\n",
        "    ONLY use data scraped from the internet for your analysis. Also provide the links where the data is sourced.\n",
        "    Extract everything in more detail.\n",
        "    If data is not available for 2024, then search for data from 2023 or previous years but ensure it is the latest report available.\n",
        "    Keep only those statements or sentences which are available on the internet, discard the sentences which are not available on the internet.\"\"\"\n",
        ")\n",
        "agents.append(partnership_analyst)\n",
        "\n",
        "swot_analyst = create_agent(\n",
        "     \"SWOT Analyst\",\n",
        "     \"Analyzes their strengths, weaknesses, opportunities, and threats (SWOT analysis) to leverage digital tools and identifies opportunities for your IT vendor's solutions to surpass them for company\",\n",
        "     \"\"\"You are an Expert in gathering and analyzing information about {company_name}'s competitior.\n",
        "    This includes their strengths, weaknesses, opportunities, and threats (SWOT analysis).\n",
        "    You need to identify potential opportunities for company to exploit and emerging threats to mitigate.\n",
        "    You need to provide valuable insights that empower leadership to make informed strategic decisions.\"\"\"\n",
        " )\n",
        "agents.append(swot_analyst)\n",
        "\n",
        "lead_analyst = create_agent(\n",
        "    \"Lead Analyst\",\n",
        "    \"Compile and synthesize reports from various analysts into a final, comprehensive document that offers a clear and actionable strategic overview.\",\n",
        "    \"\"\"Compile and synthesize all reports from various analysts into a final, comprehensive report. This report should include a dedicated section for each analyst,\n",
        "    clearly presenting their findings under appropriate headings. Each section should provide a detailed description of the insights and analyses contributed by the\n",
        "    respective analysts, ensuring that all gathered information is accurately represented and clearly communicated. The final report must offer a well-structured,\n",
        "    cohesive document that enables leadership to understand the diverse perspectives and make informed strategic decisions based on the integrated findings.\"\"\"\n",
        ")\n",
        "agents.append(lead_analyst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_E1mLzil3H-"
      },
      "outputs": [],
      "source": [
        "def create_task(description, expected_output, agent):\n",
        "    return Task(\n",
        "        description=description,\n",
        "        expected_output=expected_output,\n",
        "        agent=agent\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVf6PmZOwq-U"
      },
      "outputs": [],
      "source": [
        "tasks = [\n",
        "    create_task(\n",
        "        \"\"\"Use and summarize scraped data from the internet to make a detailed financial analysis report for {company_name}.\n",
        "        The report should include:\n",
        "        Revenue and profitability trends,\n",
        "        Major financial milestones and performance metrics,\n",
        "        Financial health indicators such as debt levels, cash flow, and liquidity,\n",
        "        Key financial ratios and their implications,\n",
        "        Comparison with industry benchmarks and competitors,\n",
        "        Use ONLY scraped data to generate the report.\n",
        "        Your final answer MUST be a full analysis report.\n",
        "        The report has to have bullet points.\n",
        "        Each bullet point MUST contain a few sentences that refer to anything you found on the internet.\n",
        "        Also provide the authentic source link from where the data is scraped.\n",
        "        Provide everything in more detail.\"\"\",\n",
        "        \"A summary of key financial metrics and insights based on the gathered financial reports.\",\n",
        "        financial_analyst\n",
        "    ),\n",
        "    create_task(\n",
        "        \"\"\"Use and summarize scraped data from the internet to make a detailed market data analysis report for {company_name}.\n",
        "        The report should include:\n",
        "        Current market trends and consumer behavior,\n",
        "        Market share and competitive positioning,\n",
        "        Key economic indicators and their impact on the company,\n",
        "        Analysis of industry reports and market research studies,\n",
        "        Future market opportunities and threats,\n",
        "        Use ONLY scraped data to generate the report.\n",
        "        Your final answer MUST be a full analysis report.\n",
        "        The report has to have bullet points.\n",
        "        Each bullet point MUST contain a few sentences that refer to anything you found on the internet.\n",
        "        Also provide the authentic source link from where the data is scraped.\n",
        "        Provide everything in more detail.\"\"\",\n",
        "        \"A summary of key market metrics and insights based on the gathered market data.\",\n",
        "        market_data_analyst\n",
        "    ),\n",
        "    create_task(\n",
        "        \"\"\"Use and summarize scraped data from the internet to make a detailed media analysis report for {company_name}.\n",
        "        The report should include:\n",
        "        Media coverage and sentiment analysis,\n",
        "        Social media presence and engagement metrics,\n",
        "        Key media campaigns and their effectiveness,\n",
        "        Public perception and brand reputation,\n",
        "        Comparison with media coverage of competitors,\n",
        "        Use ONLY scraped data to generate the report.\n",
        "        Your final answer MUST be a full analysis report.\n",
        "        The report has to have bullet points.\n",
        "        Each bullet point MUST contain a few sentences that refer to anything you found on the internet.\n",
        "        Also provide the authentic source link from where the data is scraped.\n",
        "        Provide everything in more detail.\"\"\",\n",
        "        \"A summary of key news metrics and insights based on the gathered news articles.\"\"\",\n",
        "        media_analyst\n",
        "    ),\n",
        "    create_task(\n",
        "        \"\"\"Use and summarize scraped data from the internet to make a detailed business relations analysis report for {company_name}.\n",
        "        The report should include:\n",
        "        Key business partnerships and stakeholder relationships,\n",
        "        Analysis of the company's communication and negotiation strategies,\n",
        "        Performance and impact of existing business relationships,\n",
        "        Identification of potential business opportunities and strategic alliances,\n",
        "        Comparison with competitors’ business relations strategies,\n",
        "        Use ONLY scraped data to generate the report.\n",
        "        Your final answer MUST be a full analysis report.\n",
        "        The report has to have bullet points.\n",
        "        Each bullet point MUST contain a few sentences that refer to anything you found on the internet.\n",
        "        Also provide the authentic source link from where the data is scraped.\n",
        "        Provide everything in more detail.\"\"\",\n",
        "        \"A summary of key information and insights about the company's business relationships.\",\n",
        "        business_relationships_analyst\n",
        "    ),\n",
        "    create_task(\n",
        "        \"\"\"Use and summarize scraped data from the internet to make a detailed report on the company mission, history, and core values for {company_name}.\n",
        "        The report should include:\n",
        "        Company's founding and key historical milestones,\n",
        "        Evolution of the company's mission and core values,\n",
        "        Current mission statement and how it aligns with the company's activities,\n",
        "        Vision, strategy, and ambition,\n",
        "        Comparison with industry norms and competitors' missions,\n",
        "        Use ONLY scraped data to generate the report.\n",
        "        Your final answer MUST be a full analysis report.\n",
        "        The report has to have bullet points.\n",
        "        Each bullet point MUST contain a few sentences that refer to anything you found on the internet.\n",
        "        Also provide the authentic source link from where the data is scraped.\n",
        "        Provide everything in more detail.\"\"\",\n",
        "        \"A summary of key mission, history, and core values and insights based on the gathered data.\",\n",
        "        company_mission_analyst\n",
        "    ),\n",
        "    create_task(\n",
        "        \"\"\"Use and summarize scraped data from the internet to make a detailed report on partnerships for {company_name}.\n",
        "        The report should include:\n",
        "        Key strategic partnerships and alliances,\n",
        "        Objectives and outcomes of these partnerships,\n",
        "        Partnership performance and impact on the company,\n",
        "        Potential future partnerships and strategic fit,\n",
        "        Comparison with competitors' partnerships,\n",
        "        Use ONLY scraped data to generate the report.\n",
        "        Your final answer MUST be a full analysis report.\n",
        "        The report has to have bullet points.\n",
        "        Each bullet point MUST contain a few sentences that refer to anything you found on the internet.\n",
        "        Also provide the authentic source link from where the data is scraped.\n",
        "        Provide everything in more detail.\"\"\",\n",
        "        \"A summary of key information and insights about the company's business relationships.\",\n",
        "         partnership_analyst\n",
        "    ),\n",
        "\n",
        "    create_task(\n",
        "        \"\"\"Use and summarize scraped data from the internet to make a detailed SWOT analysis report for {company_name}.\n",
        "        The report should include:\n",
        "        Strengths: Internal attributes that give the company an advantage,\n",
        "        Weaknesses: Internal attributes that place the company at a disadvantage,\n",
        "        Opportunities: External factors the company can capitalize on,\n",
        "        Threats: External factors that could jeopardize the company,\n",
        "        Detailed analysis and implications of each SWOT component,\n",
        "        Use ONLY scraped data to generate the report.\n",
        "        Your final answer MUST be a full analysis report.\n",
        "        The report has to have bullet points.\n",
        "        Each bullet point MUST contain a few sentences that refer to anything you found on the internet.\n",
        "        Also provide the authentic source link from where the data is scraped.\n",
        "        Provide everything in more detail.\"\"\",\n",
        "        \"A summary of key strengths, weaknesses, opportunities, and threats and insights based on the gathered data.\",\n",
        "        swot_analyst\n",
        "    ),\n",
        "\n",
        "    create_task(\n",
        "        \"\"\"Write a blog with information which extracted as final answer by previous agents. Do not modify them much.\n",
        "         Blog should have the report on {company_name} extracted from internet only.\n",
        "         Write about company's mission statement, history, and core values in bullet points.\n",
        "         Write about Financial Analysis report such as revenue of the company and its breakdown in detail bullet point.\n",
        "         Write about the market metrics and insights based on the gathered market data.\n",
        "         Write about the news metrics and insights based on the gathered news articles.\n",
        "         Write about revenue over days, weeks, months, quarters, or years to identify trends and seasonality in detail bullet point.\n",
        "         Write about revenue by customer type (e.g., demographics, industry) can reveal profitable customer segments, revenue by region, state, or country to understand geographical trends in detail bullet point.\n",
        "         Also Write SWOT Analysis in detail bullet point.\n",
        "         Also write about Financial Position, Global sales, Strategic Goals, Latest News, Future Goals - IT, Vendor Analysis, Digital Tech Stack  in detail bullet point\n",
        "         Name specific new, exciting projects from internet only.\n",
        "         Do not omit the information which is extracted from previous agents. Add those data as it is.\n",
        "         Extract everything in more details but everything should be come from internet. Do not write anything which is not from internet. Discard those information which is not present on internet.\n",
        "         Write the most of the data which extracted from previous agents.\n",
        "         Don't write \"**Paragraph [number of the paragraph]:**\", instead start the new paragraph in a new line.\n",
        "         Write names of projects and tools in BOLD.\n",
        "         ALWAYS include authentic source links to projects/tools/research papers. ONLY include information from scrapped data.\n",
        "         Check the source link on internet which should be present.\"\"\",\n",
        "        \"A complete, cohesive analysis report with clear headings and subheadings.\",\n",
        "        lead_analyst\n",
        "    )\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgtezhD57rt1",
        "outputId": "c5d5fadf-b217-44d5-bf71-e9693d008c65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Crew(id=26a5830f-7549-458a-a096-dbba0846472b, process=sequential, number_of_agents=8, number_of_tasks=8)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "crew = Crew(\n",
        "    agents=agents,\n",
        "    tasks=tasks,\n",
        "    verbose=True,\n",
        "    full_output = True,\n",
        "    max_rpm=600,\n",
        "    process=Process.sequential,\n",
        ")\n",
        "crew"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_company_report(company_name):\n",
        "  try:\n",
        "    result = crew.kickoff(inputs={'company_name': company_name})\n",
        "    return str(result)\n",
        "  except Exception as e:  # Catch any exception\n",
        "    return f\"An error occurred: {e}\"\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=get_company_report,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Company Profile Report\",\n",
        "    description=\"Enter a company's name to fetch its profile report.\"\n",
        ")\n",
        "\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "0wT7kLHE_KDh",
        "outputId": "4bad9002-0dba-4cdc-ea10-bb2d22693858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://aeda3631565b8dd138.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://aeda3631565b8dd138.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}